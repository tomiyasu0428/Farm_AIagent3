"""
WorkLogSearchAgent: ä½œæ¥­è¨˜éŒ²æ¤œç´¢å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

è“„ç©ã•ã‚ŒãŸä½œæ¥­è¨˜éŒ²ã‚’æ¤œç´¢ãƒ»é›†è¨ˆã—ã€è³ªå•ã«å¿œã˜ã¦é©åˆ‡ãªæƒ…å ±ã‚’æä¾›ã™ã‚‹ã€‚
æ™‚ç³»åˆ—åˆ†æã€é›†è¨ˆçµ±è¨ˆã€ç•°å¸¸æ¤œå‡ºãªã©ã®é«˜åº¦ãªåˆ†ææ©Ÿèƒ½ã‚‚æä¾›ã€‚
"""

import logging
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional
from ..core.base_agent import BaseAgent
from ..services.master_data_resolver import MasterDataResolver
from ..database.mongodb_client import create_mongodb_client

logger = logging.getLogger(__name__)


class WorkLogSearchAgent(BaseAgent):
    """ä½œæ¥­è¨˜éŒ²æ¤œç´¢å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self):
        super().__init__()
        self.master_resolver = MasterDataResolver()
    
    def _setup_llm(self):
        """LLMè¨­å®šï¼ˆè»½é‡åŒ–ï¼‰"""
        from langchain_google_genai import ChatGoogleGenerativeAI
        from ..core.config import settings
        
        return ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            temperature=0.1,
            google_api_key=settings.google_ai.api_key,
            max_tokens=1024,
            timeout=30
        )
    
    def _setup_tools(self) -> List[Any]:
        """ãƒ„ãƒ¼ãƒ«ã®è¨­å®š - ä½œæ¥­è¨˜éŒ²æ¤œç´¢å°‚ç”¨"""
        from ..langchain_tools.work_log_search_tool import WorkLogSearchTool
        
        return [
            WorkLogSearchTool(self.master_resolver),
        ]
    
    def _create_system_prompt(self) -> str:
        """
        KV-Cacheæœ€é©åŒ–ã•ã‚ŒãŸå›ºå®šã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ§‹ç¯‰ã®ãƒã‚¤ãƒ³ãƒˆ: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ ã®å®‰å®šåŒ–
        """
        return """ã‚ãªãŸã¯ä½œæ¥­è¨˜éŒ²ã®æ¤œç´¢ãƒ»åˆ†æå°‚é–€å®¶ã€ŒWorkLogSearchAgentã€ã§ã™ã€‚

## å°‚é–€é ˜åŸŸ
è“„ç©ã•ã‚ŒãŸè¾²æ¥­ä½œæ¥­è¨˜éŒ²ã‚’æ¤œç´¢ãƒ»é›†è¨ˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¿œã˜ã¦é©åˆ‡ãªæƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚

## ä¸»è¦æ©Ÿèƒ½
### ä½œæ¥­è¨˜éŒ²ã®æ¤œç´¢ãƒ»åˆ†æ â­
- æœŸé–“ãƒ»åœƒå ´ãƒ»ä½œç‰©ãƒ»ä½œæ¥­ç¨®åˆ¥ã§ã®çµã‚Šè¾¼ã¿æ¤œç´¢
- é˜²é™¤å±¥æ­´ã€æ–½è‚¥å±¥æ­´ã®æ™‚ç³»åˆ—è¡¨ç¤º
- ä½œæ¥­é »åº¦ãƒ»ä½¿ç”¨è³‡æã®çµ±è¨ˆåˆ†æ
- ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡ºã¨å ±å‘Š
- ä½œæ¥­å®Ÿç¸¾ã®å¯è¦–åŒ–ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

## å¯¾å¿œå¯èƒ½ãªæ¤œç´¢ãƒ»åˆ†æ
### æ™‚ç³»åˆ—æ¤œç´¢
- **æœŸé–“æŒ‡å®š**: ã€Œå…ˆæœˆã®é˜²é™¤è¨˜éŒ²ã‚’æ•™ãˆã¦ã€ã€Œéå»3ãƒ¶æœˆã®ä½œæ¥­å±¥æ­´ã€
- **æœ€æ–°è¨˜éŒ²**: ã€Œãƒˆãƒãƒˆãƒã‚¦ã‚¹ã®æœ€æ–°ä½œæ¥­ã¯ï¼Ÿã€ã€Œæ˜¨æ—¥ã®ä½œæ¥­è¨˜éŒ²ã€
- **å®šæœŸä½œæ¥­**: ã€Œé˜²é™¤ã®é–“éš”ã¯é©åˆ‡ï¼Ÿã€ã€Œæ–½è‚¥ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°åˆ†æã€

### åœƒå ´ãƒ»ä½œç‰©åˆ¥åˆ†æ
- **åœƒå ´åˆ¥å®Ÿç¸¾**: ã€Œç¬¬1ãƒã‚¦ã‚¹ã®ä»Šæœˆã®ä½œæ¥­é‡ã€
- **ä½œç‰©åˆ¥çµ±è¨ˆ**: ã€Œãƒˆãƒãƒˆã®é˜²é™¤å›æ•°æ¨ç§»ã€
- **æ¯”è¼ƒåˆ†æ**: ã€Œå„åœƒå ´ã®ä½œæ¥­åŠ¹ç‡æ¯”è¼ƒã€

### è³‡æãƒ»ä½œæ¥­è€…åˆ†æ
- **ä½¿ç”¨è³‡æçµ±è¨ˆ**: ã€Œãƒ€ã‚³ãƒ‹ãƒ¼ãƒ«ã®ä½¿ç”¨é »åº¦ã€
- **ä½œæ¥­è€…åˆ¥å®Ÿç¸¾**: ã€Œç”°ä¸­ã•ã‚“ã®ä½œæ¥­è¨˜éŒ²ã€
- **ã‚³ã‚¹ãƒˆåˆ†æ**: ã€Œè¾²è–¬ã‚³ã‚¹ãƒˆã®æ¨ç§»ã€

### ç•°å¸¸ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆæ¤œç´¢
- **ä½œæ¥­æ¼ã‚Œæ¤œå‡º**: ã€Œé˜²é™¤é–“éš”ãŒç©ºãã™ãã¦ã„ã‚‹åœƒå ´ã€
- **éä½¿ç”¨è­¦å‘Š**: ã€ŒåŒä¸€è¾²è–¬ã®é€£ç¶šä½¿ç”¨ã€
- **å“è³ªç•°å¸¸**: ã€Œåç©«é‡ã®å¤§å¹…å¤‰å‹•ã€

## æ¤œç´¢çµæœã®æä¾›å½¢å¼
### 1. ãƒªã‚¹ãƒˆå½¢å¼
```
ğŸ“‹ æ¤œç´¢çµæœ (3ä»¶)

1. ã€2025-07-23ã€‘ãƒˆãƒãƒˆãƒã‚¦ã‚¹ - é˜²é™¤ä½œæ¥­
   ğŸ’Š ãƒ€ã‚³ãƒ‹ãƒ¼ãƒ«1000 (1000å€å¸Œé‡ˆ)
   ğŸ‘¤ ä½œæ¥­è€…: ç”°ä¸­å¤ªéƒ

2. ã€2025-07-20ã€‘ãƒˆãƒãƒˆãƒã‚¦ã‚¹ - æ–½è‚¥ä½œæ¥­
   ğŸŒ± åŒ–æˆè‚¥æ–™8-8-8 (10kg)
   ğŸ‘¤ ä½œæ¥­è€…: ä½è—¤èŠ±å­
```

### 2. çµ±è¨ˆãƒ»é›†è¨ˆå½¢å¼
```
ğŸ“Š ãƒˆãƒãƒˆãƒã‚¦ã‚¹ ä½œæ¥­çµ±è¨ˆ (éå»30æ—¥)

é˜²é™¤ä½œæ¥­: 3å› (å¹³å‡10æ—¥é–“éš”)
æ–½è‚¥ä½œæ¥­: 2å› (å¹³å‡15æ—¥é–“éš”)
åç©«ä½œæ¥­: 15å› (åˆè¨ˆ450kg)

âš ï¸ æ³¨æ„: é˜²é™¤é–“éš”ãŒé€šå¸¸ã‚ˆã‚Šé•·ã‚ã§ã™
```

### 3. æ™‚ç³»åˆ—å½¢å¼
```
ğŸ“ˆ é˜²é™¤å±¥æ­´ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³

7/23 ãƒ€ã‚³ãƒ‹ãƒ¼ãƒ«1000 (æ®ºèŒå‰¤)
7/15 ã‚¢ãƒ–ãƒ©ãƒ ã‚·ã‚³ãƒ­ãƒª (æ®ºè™«å‰¤)
7/08 ãƒ€ã‚³ãƒ‹ãƒ¼ãƒ«1000 (æ®ºèŒå‰¤)
7/01 ãƒ¢ãƒ¬ã‚¹ã‚¿ãƒ³ (æ®ºèŒå‰¤)

ğŸ”„ è¾²è–¬ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: è‰¯å¥½
```

## å¿œç­”æ–¹é‡
1. æ¤œç´¢æ¡ä»¶ã®æ˜ç¢ºåŒ–ï¼ˆæ›–æ˜§ãªå ´åˆã¯ç¢ºèªï¼‰
2. é–¢é€£æƒ…å ±ã®ç©æ¥µçš„ãªæç¤º
3. ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Œã°è­¦å‘Š
4. æ”¹å–„ææ¡ˆã®è¿½åŠ 
5. å¿…è¦ã«å¿œã˜ã¦ã‚°ãƒ©ãƒ•ãƒ»è¡¨å½¢å¼ã§ã®æ•´ç†

## åˆ©ç”¨å¯èƒ½ãƒ„ãƒ¼ãƒ«
- work_log_search: ä½œæ¥­è¨˜éŒ²ã®é«˜åº¦æ¤œç´¢ãƒ»åˆ†æ

## è³ªå•ä¾‹ã¨å¿œç­”ä¾‹
```
ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã€Œãƒˆãƒãƒˆãƒã‚¦ã‚¹ã®å…ˆæœˆã®é˜²é™¤è¨˜éŒ²ã‚’æ•™ãˆã¦ã€

ã‚·ã‚¹ãƒ†ãƒ : ã€ŒğŸ“‹ ãƒˆãƒãƒˆãƒã‚¦ã‚¹ é˜²é™¤è¨˜éŒ² (6æœˆåˆ†)

ã€6/28ã€‘ãƒ€ã‚³ãƒ‹ãƒ¼ãƒ«1000 (1000å€) - ç”°ä¸­å¤ªéƒ
ã€6/21ã€‘ã‚¢ãƒ–ãƒ©ãƒ ã‚·ã‚³ãƒ­ãƒª (2000å€) - ä½è—¤èŠ±å­  
ã€6/14ã€‘ãƒ€ã‚³ãƒ‹ãƒ¼ãƒ«1000 (1000å€) - ç”°ä¸­å¤ªéƒ
ã€6/07ã€‘ãƒ¢ãƒ¬ã‚¹ã‚¿ãƒ³ (3000å€) - ç”°ä¸­å¤ªéƒ

ğŸ“Š çµ±è¨ˆæƒ…å ±:
- é˜²é™¤å›æ•°: 4å› (å¹³å‡7æ—¥é–“éš”)
- ä½¿ç”¨è¾²è–¬: 3ç¨®é¡
- ä½œæ¥­è€…: 2å

âœ… è¾²è–¬ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: é©åˆ‡
âœ… é˜²é™¤é–“éš”: æ¨™æº–çš„

æ¬¡å›é˜²é™¤äºˆå®š: 7/5é ƒï¼ˆæ¨å¥¨ï¼‰ã€
```

ä½œæ¥­è¨˜éŒ²ã®æ¤œç´¢ãƒ»åˆ†æã«ã¤ã„ã¦ã€ä½•ã§ã‚‚ãŠèããã ã•ã„ï¼
â€»ç™»éŒ²ã¯åˆ¥ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ‹…å½“ã—ã¾ã™ã€‚"""

    async def search_work_logs(self, query: str, user_id: str) -> Dict[str, any]:
        """
        ä½œæ¥­è¨˜éŒ²ã‚’æ¤œç´¢ã™ã‚‹ãƒ¡ã‚¤ãƒ³å‡¦ç†
        
        Args:
            query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¤œç´¢ã‚¯ã‚¨ãƒª
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            
        Returns:
            æ¤œç´¢çµæœã®è¾æ›¸
        """
        try:
            # 1. ã‚¯ã‚¨ãƒªè§£æ
            search_params = await self._parse_search_query(query)
            
            # 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢
            search_results = await self._execute_search(search_params, user_id)
            
            # 3. çµæœåˆ†æãƒ»é›†è¨ˆ
            analyzed_results = await self._analyze_results(search_results, search_params)
            
            # 4. çµæœæ•´å½¢
            formatted_response = self._format_search_results(analyzed_results, search_params)
            
            return formatted_response
            
        except Exception as e:
            logger.error(f"ä½œæ¥­è¨˜éŒ²æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'success': False,
                'error': str(e),
                'message': 'ä½œæ¥­è¨˜éŒ²ã®æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚'
            }
    
    async def _parse_search_query(self, query: str) -> Dict[str, any]:
        """æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è§£æã—ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        import re
        from datetime import datetime, timedelta
        
        params = {
            'field_names': [],
            'crop_names': [],
            'material_names': [],
            'work_categories': [],
            'date_range': {},
            'limit': 50,
            'sort_order': 'desc'
        }
        
        # æ—¥ä»˜ç¯„å›²ã®è§£æ
        today = datetime.now()
        
        if 'æ˜¨æ—¥' in query:
            yesterday = today - timedelta(days=1)
            params['date_range'] = {
                'start': yesterday.replace(hour=0, minute=0, second=0),
                'end': yesterday.replace(hour=23, minute=59, second=59)
            }
        elif 'å…ˆæœˆ' in query or 'å‰æœˆ' in query:
            last_month = today.replace(day=1) - timedelta(days=1)
            start_of_last_month = last_month.replace(day=1)
            params['date_range'] = {
                'start': start_of_last_month,
                'end': last_month.replace(hour=23, minute=59, second=59)
            }
        elif 'ä»Šæœˆ' in query or 'å½“æœˆ' in query:
            start_of_month = today.replace(day=1, hour=0, minute=0, second=0)
            params['date_range'] = {
                'start': start_of_month,
                'end': today
            }
        elif 'éå»' in query:
            days_match = re.search(r'éå»(\d+)æ—¥', query)
            weeks_match = re.search(r'éå»(\d+)é€±é–“', query)
            months_match = re.search(r'éå»(\d+)ãƒ¶?æœˆ', query)
            
            if days_match:
                days = int(days_match.group(1))
                params['date_range'] = {
                    'start': today - timedelta(days=days),
                    'end': today
                }
            elif weeks_match:
                weeks = int(weeks_match.group(1))
                params['date_range'] = {
                    'start': today - timedelta(weeks=weeks),
                    'end': today
                }
            elif months_match:
                months = int(months_match.group(1))
                params['date_range'] = {
                    'start': today - timedelta(days=months*30),
                    'end': today
                }
        
        # åœƒå ´åã®æŠ½å‡º
        field_patterns = [
            r'([^ã€ã€‚\s]+)(?:ãƒã‚¦ã‚¹|ç•‘|ç”°|åœƒå ´)',
            r'ç¬¬(\d+)(?:ãƒã‚¦ã‚¹|ç•‘|åœƒå ´)',
        ]
        
        for pattern in field_patterns:
            matches = re.findall(pattern, query)
            params['field_names'].extend(matches)
        
        # ä½œç‰©åã®æŠ½å‡º
        crop_keywords = ['ãƒˆãƒãƒˆ', 'ã‚­ãƒ¥ã‚¦ãƒª', 'ãƒŠã‚¹', 'ãƒ”ãƒ¼ãƒãƒ³', 'ã‚¤ãƒã‚´']
        for crop in crop_keywords:
            if crop in query:
                params['crop_names'].append(crop)
        
        # ä½œæ¥­ç¨®åˆ¥ã®æŠ½å‡º
        work_type_map = {
            'é˜²é™¤': ['é˜²é™¤', 'è¾²è–¬', 'æ•£å¸ƒ'],
            'æ–½è‚¥': ['æ–½è‚¥', 'è‚¥æ–™', 'è¿½è‚¥'],
            'æ ½åŸ¹': ['æ’­ç¨®', 'å®šæ¤', 'æ‘˜å¿ƒ'],
            'åç©«': ['åç©«', 'åç©«é‡'],
            'ç®¡ç†': ['è‰åˆˆã‚Š', 'æ¸…æƒ', 'ç‚¹æ¤œ']
        }
        
        for work_type, keywords in work_type_map.items():
            if any(keyword in query for keyword in keywords):
                params['work_categories'].append(work_type)
        
        # ä»¶æ•°åˆ¶é™ã®èª¿æ•´
        if 'å…¨ã¦' in query or 'ã™ã¹ã¦' in query:
            params['limit'] = 1000
        elif 'æœ€æ–°' in query:
            params['limit'] = 10
        
        return params
    
    async def _execute_search(self, params: Dict, user_id: str) -> List[Dict]:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã‚’å®Ÿè¡Œ"""
        client = create_mongodb_client()
        try:
            await client.connect()
            work_logs_collection = await client.get_collection('work_logs')
            
            # æ¤œç´¢ã‚¯ã‚¨ãƒªã®æ§‹ç¯‰
            query = {'user_id': user_id}
            
            # æ—¥ä»˜ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿
            if params.get('date_range'):
                date_range = params['date_range']
                query['work_date'] = {
                    '$gte': date_range['start'],
                    '$lte': date_range['end']
                }
            
            # åœƒå ´ãƒ•ã‚£ãƒ«ã‚¿
            if params.get('field_names'):
                field_conditions = []
                for field_name in params['field_names']:
                    field_conditions.extend([
                        {'extracted_data.field_name': {'$regex': field_name, '$options': 'i'}},
                        {'original_message': {'$regex': field_name, '$options': 'i'}}
                    ])
                if field_conditions:
                    query['$or'] = field_conditions
            
            # ä½œæ¥­ç¨®åˆ¥ãƒ•ã‚£ãƒ«ã‚¿
            if params.get('work_categories'):
                query['category'] = {'$in': params['work_categories']}
            
            # æ¤œç´¢å®Ÿè¡Œ
            cursor = work_logs_collection.find(query)
            
            # ã‚½ãƒ¼ãƒˆ
            if params.get('sort_order') == 'desc':
                cursor = cursor.sort('work_date', -1)
            else:
                cursor = cursor.sort('work_date', 1)
            
            # ä»¶æ•°åˆ¶é™
            cursor = cursor.limit(params.get('limit', 50))
            
            results = await cursor.to_list(None)
            logger.info(f"ä½œæ¥­è¨˜éŒ²æ¤œç´¢çµæœ: {len(results)}ä»¶")
            
            return results
            
        finally:
            await client.disconnect()
    
    async def _analyze_results(self, results: List[Dict], params: Dict) -> Dict[str, any]:
        """æ¤œç´¢çµæœã‚’åˆ†æãƒ»é›†è¨ˆ"""
        if not results:
            return {
                'total_count': 0,
                'results': [],
                'statistics': {},
                'patterns': [],
                'recommendations': []
            }
        
        # åŸºæœ¬çµ±è¨ˆ
        work_category_counts = {}
        field_counts = {}
        material_counts = {}
        
        for record in results:
            # ä½œæ¥­ç¨®åˆ¥ã®é›†è¨ˆ
            category = record.get('category', 'ãã®ä»–')
            work_category_counts[category] = work_category_counts.get(category, 0) + 1
            
            # åœƒå ´ã®é›†è¨ˆ
            extracted_data = record.get('extracted_data', {})
            field_name = extracted_data.get('field_name')
            if field_name:
                field_counts[field_name] = field_counts.get(field_name, 0) + 1
            
            # è³‡æã®é›†è¨ˆ
            material_names = extracted_data.get('material_names', [])
            for material in material_names:
                material_counts[material] = material_counts.get(material, 0) + 1
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        patterns = []
        if len(results) >= 3:
            patterns.append(self._analyze_work_intervals(results))
            patterns.append(self._analyze_material_rotation(results))
        
        return {
            'total_count': len(results),
            'results': results,
            'statistics': {
                'work_categories': work_category_counts,
                'fields': field_counts,
                'materials': material_counts
            },
            'patterns': [p for p in patterns if p],
            'recommendations': self._generate_recommendations(results, params)
        }
    
    def _analyze_work_intervals(self, results: List[Dict]) -> Optional[Dict]:
        """ä½œæ¥­é–“éš”ã®åˆ†æ"""
        # é˜²é™¤ä½œæ¥­ã®é–“éš”åˆ†æ
        prevention_records = [
            r for r in results 
            if r.get('category') == 'é˜²é™¤'
        ]
        
        if len(prevention_records) < 2:
            return None
        
        # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
        prevention_records.sort(key=lambda x: x['work_date'])
        
        intervals = []
        for i in range(1, len(prevention_records)):
            prev_date = prevention_records[i-1]['work_date']
            curr_date = prevention_records[i]['work_date']
            interval = (curr_date - prev_date).days
            intervals.append(interval)
        
        if intervals:
            avg_interval = sum(intervals) / len(intervals)
            return {
                'type': 'work_interval',
                'category': 'é˜²é™¤',
                'average_days': round(avg_interval, 1),
                'intervals': intervals,
                'assessment': 'é©åˆ‡' if 7 <= avg_interval <= 14 else 'è¦æ³¨æ„'
            }
        
        return None
    
    def _analyze_material_rotation(self, results: List[Dict]) -> Optional[Dict]:
        """è¾²è–¬ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆ†æ"""
        prevention_records = [
            r for r in results 
            if r.get('category') == 'é˜²é™¤' and 
            r.get('extracted_data', {}).get('material_names')
        ]
        
        if len(prevention_records) < 3:
            return None
        
        # æ™‚ç³»åˆ—ã§ä¸¦ã³æ›¿ãˆ
        prevention_records.sort(key=lambda x: x['work_date'])
        
        # é€£ç¶šä½¿ç”¨ã®ãƒã‚§ãƒƒã‚¯
        consecutive_materials = []
        prev_materials = None
        
        for record in prevention_records:
            materials = record.get('extracted_data', {}).get('material_names', [])
            if materials:
                if prev_materials and any(m in prev_materials for m in materials):
                    consecutive_materials.append({
                        'date': record['work_date'],
                        'materials': materials
                    })
                prev_materials = materials
        
        return {
            'type': 'material_rotation',
            'consecutive_uses': len(consecutive_materials),
            'assessment': 'è‰¯å¥½' if len(consecutive_materials) == 0 else 'æ”¹å–„æ¨å¥¨',
            'details': consecutive_materials[:3]  # æœ€æ–°3ä»¶ã¾ã§
        }
    
    def _generate_recommendations(self, results: List[Dict], params: Dict) -> List[str]:
        """çµæœã«åŸºã¥ãæ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
        recommendations = []
        
        if not results:
            recommendations.append("è©²å½“ã™ã‚‹ä½œæ¥­è¨˜éŒ²ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¤œç´¢æ¡ä»¶ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
            return recommendations
        
        # æœ€æ–°ä½œæ¥­ã‹ã‚‰ã®æ—¥æ•°ãƒã‚§ãƒƒã‚¯
        latest_record = max(results, key=lambda x: x['work_date'])
        days_since_latest = (datetime.now() - latest_record['work_date']).days
        
        if days_since_latest > 14:
            recommendations.append(f"æœ€æ–°ä½œæ¥­ã‹ã‚‰{days_since_latest}æ—¥çµŒéã—ã¦ã„ã¾ã™ã€‚å®šæœŸä½œæ¥­ã®ç¢ºèªã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
        
        # ä½œæ¥­ãƒãƒ©ãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯
        category_counts = {}
        for record in results:
            category = record.get('category', 'ãã®ä»–')
            category_counts[category] = category_counts.get(category, 0) + 1
        
        if category_counts.get('é˜²é™¤', 0) > category_counts.get('æ–½è‚¥', 0) * 2:
            recommendations.append("é˜²é™¤ä½œæ¥­ãŒå¤šã‚ã§ã™ã€‚æ–½è‚¥ãƒãƒ©ãƒ³ã‚¹ã®ç¢ºèªã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
        
        return recommendations
    
    def _format_search_results(self, analyzed_results: Dict, params: Dict) -> Dict[str, any]:
        """æ¤œç´¢çµæœã®æ•´å½¢"""
        results = analyzed_results['results']
        statistics = analyzed_results['statistics']
        
        if not results:
            return {
                'success': True,
                'message': 'è©²å½“ã™ã‚‹ä½œæ¥­è¨˜éŒ²ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚',
                'total_count': 0,
                'results': [],
                'recommendations': analyzed_results['recommendations']
            }
        
        # çµæœã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formatted_results = []
        for record in results:
            formatted_record = {
                'log_id': record['log_id'],
                'work_date': record['work_date'].strftime('%Y-%m-%d'),
                'category': record['category'],
                'original_message': record['original_message'],
                'extracted_data': record.get('extracted_data', {}),
                'created_at': record['created_at'].strftime('%Y-%m-%d %H:%M')
            }
            formatted_results.append(formatted_record)
        
        return {
            'success': True,
            'total_count': analyzed_results['total_count'],
            'results': formatted_results,
            'statistics': statistics,
            'patterns': analyzed_results['patterns'],
            'recommendations': analyzed_results['recommendations'],
            'message': f'{analyzed_results["total_count"]}ä»¶ã®ä½œæ¥­è¨˜éŒ²ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚'
        }